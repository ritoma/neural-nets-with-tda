# -*- coding: utf-8 -*-
"""cifar10_eval

Automatically generated by Colaboratory.
"""

import numpy as np
import tensorflow.compat.v2 as tf
import time

tf.enable_v2_behavior()

from pllay import *

"""# Evaluation"""

nmax_diag = 32


from models import *

def cifar10_eval(nTimes, corrupt_prob_list, noise_prob_list,
      x_processed_file_list, y_file, model_mlp_file_array,
      model_mlp_pllay_file_array, model_cnn_file_array,
      model_cnn_pllay_file_array, model_cnn_pllay_input_file_array,
      batch_size=16):

    print("nTimes = ", nTimes)

    accuracy_mlp = np.zeros(nTimes)
    accuracy_mlp_pllay = np.zeros(nTimes)
    accuracy_cnn = np.zeros(nTimes)
    accuracy_cnn_pllay = np.zeros(nTimes)
    accuracy_cnn_pllay_input = np.zeros(nTimes)

    (y_train, y_test) = np.load(y_file, allow_pickle=True)

    for iCn in range(nCn):
        start_time = time.time()
        print("--------------------------------------------------------------")
        print("Corruption rate = ", corrupt_prob_list[iCn])
        print("Noise rate = ", noise_prob_list[iCn])
        print("--------------------------------------------------------------")

        (x_train_processed, x_test_processed) = np.load(
              x_processed_file_list[iCn], allow_pickle=True)
        test_dataset = to_tf_dataset(x=x_test_processed, y=y_test,
              batch_size=batch_size)

        for iTime in range(nTimes):
            """
            # MLP
            start_time_inside = time.time()
            print("MLP")
            model_mlp = cifar10_MLP()
            model_mlp.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['sparse_categorical_accuracy'])
            model_mlp.load_weights(
                  model_mlp_file_array[iCn][iTime])
            accuracy_mlp[iTime] = model_mlp.evaluate(test_dataset)[1]
            print("--- %s seconds ---" % (time.time() - start_time_inside))

            # MLP + PLLay
            start_time_inside = time.time()
            print("MLP + PLLay")
            model_mlp_pllay = cifar10_MLP_PLLay()
            model_mlp_pllay.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['sparse_categorical_accuracy'])
            model_mlp_pllay.load_weights(
                  model_mlp_pllay_file_array[iCn][iTime])
            accuracy_mlp_pllay[iTime] = model_mlp_pllay.evaluate(
                  test_dataset)[1]
            print("--- %s seconds ---" % (time.time() - start_time_inside))
            """

            # CNN
            start_time_inside = time.time()
            print("CNN")
            model_cnn = CIFAR10_CNN()
            model_cnn.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['sparse_categorical_accuracy'])
            model_cnn.load_weights(
                  model_cnn_file_array[iCn][iTime])
            accuracy_cnn[iTime] = model_cnn.evaluate(test_dataset)[1]
            print("--- %s seconds ---" % (time.time() - start_time_inside))

            # CNN + PLLay
            start_time_inside = time.time()
            print("CNN + PLLay")
            model_cnn_pllay = CIFAR10_CNN_PLLay()
            model_cnn_pllay.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['sparse_categorical_accuracy'])
            model_cnn_pllay.load_weights(
                  model_cnn_pllay_file_array[iCn][iTime])
            accuracy_cnn_pllay[iTime] = model_cnn_pllay.evaluate(
                  test_dataset)[1]
            print("--- %s seconds ---" % (time.time() - start_time_inside))

            """
            # CNN + PLLay, input only
            start_time_inside = time.time()
            print("CNN + PLLay, input only")
            model_cnn_pllay_input = cifar10_CNN_PLLay_Input()
            model_cnn_pllay_input.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['sparse_categorical_accuracy'])
            model_cnn_pllay_input.load_weights(
                  model_cnn_pllay_input_file_array[iCn][iTime])
            accuracy_cnn_pllay_input[iTime] = model_cnn_pllay_input.evaluate(
                  test_dataset)[1]
            print("--- %s seconds ---" % (time.time() - start_time_inside))
            """

        print("--------------------------------------------------------------")
        print("Corruption rate = ", corrupt_prob_list[iCn])
        print("Noise rate = ", noise_prob_list[iCn])
        print("--------------------------------------------------------------") 
        print("Accuracy for MLP : ", accuracy_mlp)
        print("Average Accuracy for MLP : ", sum(accuracy_mlp) / nTimes)
        print("Accuracy for MLP + PLLay :", accuracy_mlp_pllay)
        print("Average Accuracy for MLP + PLLay :",
              sum(accuracy_mlp_pllay) / nTimes)
        """
        print("Accuracy for CNN :", accuracy_cnn)
        print("Average Accuracy for CNN :", sum(accuracy_cnn) / nTimes)
        print("Accuracy for CNN + PLLay :", accuracy_cnn_pllay)
        print("Average Accuracy for CNN + PLLay :",
              sum(accuracy_cnn_pllay) / nTimes)
        print("Accuracy for CNN + PLLay, input only :",
              accuracy_cnn_pllay_input)
        print("Average Accuracy for CNN + PLLay, input only :",
              sum(accuracy_cnn_pllay_input) / nTimes)
        """

        print("--- %s seconds ---" % (time.time() - start_time))
        print("--------------------------------------------------------------")

# corrupt_prob_list = [0.1]
# noise_prob_list = [0.1]
corrupt_prob_list = [0.0, 0.1, 0.2, 0.3]
noise_prob_list = [0.0, 0.1, 0.2, 0.3]
nCn = len(corrupt_prob_list)
file_cn_list = [None] * nCn
for iCn in range(nCn):
    file_cn_list[iCn] = str(int(corrupt_prob_list[iCn] * 100)).zfill(2) + \
          '_' + str(int(noise_prob_list[iCn] * 100)).zfill(2)

x_processed_file_list = [None] * nCn
for iCn in range(nCn):
    x_processed_file_list[iCn] = (
          'cifar10_x_processed_' + file_cn_list[iCn] + '.npy')
y_file = 'cifar10_y.npy'

# nTimes=1
nTimes=1
model_mlp_file_array = [None] * nCn
model_mlp_pllay_file_array = [None] * nCn
model_cnn_file_array = [None] * nCn
model_cnn_pllay_file_array = [None] * nCn
model_cnn_pllay_input_file_array = [None] * nCn
for iCn in range(nCn):
    model_mlp_file_array[iCn] = [None] * nTimes
    model_mlp_pllay_file_array[iCn] = [None] * nTimes
    model_cnn_file_array[iCn] = [None] * nTimes
    model_cnn_pllay_file_array[iCn] = [None] * nTimes
    model_cnn_pllay_input_file_array[iCn] = [None] * nTimes
for iCn in range(nCn):
    for iTime in range(nTimes):
        file_time = str(iTime).zfill(2)
        model_mlp_file_array[iCn][iTime] = 'cifar10_models_20000/mlp_' + \
              file_cn_list[iCn] + '_' + file_time + '/model'
        model_mlp_pllay_file_array[iCn][iTime] = 'cifar10_models_20000/mlp_pllay_' + \
              file_cn_list[iCn] + '_' + file_time + '/model'
        model_cnn_file_array[iCn][iTime] = 'cifar10_models_20000/cnn_' + \
              file_cn_list[iCn] + '_' + file_time + '/model'
        model_cnn_pllay_file_array[iCn][iTime] = 'cifar10_models_20000/cnn_pllay_' + \
              file_cn_list[iCn] + '_' + file_time + '/model'
        model_cnn_pllay_input_file_array[iCn][iTime] = \
              'cifar10_models_20000/cnn_pllay_input_' + file_cn_list[iCn] + '_' + \
              file_time + '/model'

batch_size = 8

cifar10_eval(nTimes=nTimes, corrupt_prob_list=corrupt_prob_list,
      noise_prob_list=noise_prob_list,
      x_processed_file_list=x_processed_file_list, y_file=y_file,
      model_mlp_file_array=model_mlp_file_array,
      model_mlp_pllay_file_array=model_mlp_pllay_file_array,
      model_cnn_file_array=model_cnn_file_array,
      model_cnn_pllay_file_array=model_cnn_pllay_file_array,
      model_cnn_pllay_input_file_array=model_cnn_pllay_input_file_array,
      batch_size=batch_size)