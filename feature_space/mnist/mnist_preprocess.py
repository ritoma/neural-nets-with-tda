# -*- coding: utf-8 -*-
"""mnist_preprocess

Automatically generated by Colaboratory.
"""

import numpy as np

from pllay import *

"""#Preprocessing"""

def preprocess_pllay(x_train, x_test, lims, by, r, dimensions, m0_05,
      tseq05, KK05, m0_20, tseq20, KK20, batch_size=16):

    x_landscape05_train = compute_landscape_dtmweight(X=x_train, m0=m0_05,
          lims=lims, by=by, r=r, tseq=tseq05, KK=KK05, dimensions=dimensions,
          batch_size=batch_size)
    x_landscape20_train = compute_landscape_dtmweight(X=x_train, m0=m0_20,
          lims=lims, by=by, r=r, tseq=tseq20, KK=KK20, dimensions=dimensions,
          batch_size=batch_size)
    x_landscape05_test = compute_landscape_dtmweight(X=x_test, m0=m0_05,
          lims=lims, by=by, r=r, tseq=tseq05, KK=KK05, dimensions=dimensions,
          batch_size=batch_size)
    x_landscape20_test = compute_landscape_dtmweight(X=x_test, m0=m0_20,
          lims=lims, by=by, r=r, tseq=tseq20, KK=KK20, dimensions=dimensions,
          batch_size=batch_size)

    return (x_landscape05_train, x_landscape20_train, x_landscape05_test,
          x_landscape20_test)


def preprocess_slay(x_train, x_test, lims, by, r, dimensions, m0_05, tseq05,
      KK05, m0_20, tseq20, KK20, maxscale, nmax_diag, batch_size=16):

    x_diag05_train = compute_diagram_dtmweight(X=x_train, m0=m0_05, lims=lims,
          by=by, r=r, tseq=tseq05, KK=KK05, dimensions=dimensions,
          maxscale=maxscale, nmax_diag=nmax_diag, batch_size=batch_size)
    x_diag20_train = compute_diagram_dtmweight(X=x_train, m0=m0_20, lims=lims,
          by=by, r=r, tseq=tseq20, KK=KK20, dimensions=dimensions,
          maxscale=maxscale, nmax_diag=nmax_diag, batch_size=batch_size)
    x_diag05_test = compute_diagram_dtmweight(X=x_test, m0=m0_05, lims=lims,
          by=by, r=r, tseq=tseq05, KK=KK05, dimensions=dimensions,
          maxscale=maxscale, nmax_diag=nmax_diag, batch_size=batch_size)
    x_diag20_test = compute_diagram_dtmweight(X=x_test, m0=m0_20, lims=lims,
          by=by, r=r, tseq=tseq20, KK=KK20, dimensions=dimensions,
          maxscale=maxscale, nmax_diag=nmax_diag, batch_size=batch_size)

    return (x_diag05_train, x_diag20_train, x_diag05_test, x_diag20_test)


def mnist_preprocess(lims, by, r, dimensions, m0_05, tseq05, KK05, m0_20,
      tseq20, KK20, maxscale, nmax_diag, x_original_file_list,
      x_processed_file_list, batch_size=16):

    for iCn in range(nCn):
        (x_train, x_test) = np.load(x_original_file_list[iCn],
              allow_pickle=True)

        (x_landscape05_train, x_landscape20_train, x_landscape05_test, x_landscape20_test) = (
              preprocess_pllay(x_train=x_train, x_test=x_test, lims=lims,
              by=by, r=r, dimensions=dimensions, m0_05=m0_05, tseq05=tseq05,
              KK05=KK05, m0_20=m0_20, tseq20=tseq20, KK20=KK20,
              batch_size=batch_size))

        (x_diag05_train, x_diag20_train, x_diag05_test, x_diag20_test) = (
              preprocess_slay(x_train=x_train, x_test=x_test, lims=lims,
              by=by, r=r, dimensions=dimensions, m0_05=m0_05, tseq05=tseq05,
              KK05=KK05, m0_20=m0_20, tseq20=tseq20, KK20=KK20,
              maxscale=maxscale, nmax_diag=nmax_diag, batch_size=batch_size))

        x_train_processed = np.hstack((x_train.reshape(len(x_train), 784),
              x_landscape05_train.reshape(len(x_train), 100),
              x_landscape20_train.reshape(len(x_train), 162),
              x_diag05_train.reshape(len(x_train), 4 * nmax_diag),
              x_diag20_train.reshape(len(x_train), 4 * nmax_diag)))
        x_test_processed = np.hstack((x_test.reshape(len(x_test), 784),
              x_landscape05_test.reshape(len(x_test), 100),
              x_landscape20_test.reshape(len(x_test), 162),
              x_diag05_test.reshape(len(x_test), 4 * nmax_diag),
              x_diag20_test.reshape(len(x_test), 4 * nmax_diag)))
        np.save(x_processed_file_list[iCn],
              (x_train_processed, x_test_processed))

corrupt_prob_list = [0.1]
noise_prob_list = [0.1]
#corrupt_prob_list = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35]
#noise_prob_list = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35]
nCn = len(corrupt_prob_list)
file_cn_list = [None] * nCn
for iCn in range(nCn):
    file_cn_list[iCn] = str(int(corrupt_prob_list[iCn] * 100)).zfill(2) + \
          '_' + str(int(noise_prob_list[iCn] * 100)).zfill(2)

x_original_file_list = [None] * nCn
for iCn in range(nCn):
    x_original_file_list[iCn] = (
          'mnist_x_original_' + file_cn_list[iCn] + '.npy')

x_processed_file_list = [None] * nCn
for iCn in range(nCn):
    x_processed_file_list[iCn] = (
          'mnist_x_processed_' + file_cn_list[iCn] + '.npy')

lims = [[-1., 1.], [-1., 1.]]
by = 1/13.5
r = 2.
dimensions = [0, 1]

m0_05 = 0.05
tseq05 = np.linspace(0.06, 0.3, 25)
KK05 = list(range(2))

m0_20 = 0.20
tseq20 = np.linspace(0.14, 0.4, 27)
KK20 = list(range(3))

batch_size = 16

nmax_diag = 32
maxscale = 1.

mnist_preprocess(lims=lims, by=by, r=r, dimensions=dimensions, m0_05=m0_05,
      tseq05=tseq05, KK05=KK05, m0_20=m0_20, tseq20=tseq20, KK20=KK20,
      maxscale=maxscale, nmax_diag=nmax_diag,
      x_original_file_list=x_original_file_list,
      x_processed_file_list=x_processed_file_list,
      batch_size=batch_size)